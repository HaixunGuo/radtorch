<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.4" />
<title>radtorch.pipeline API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116382803-2"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-116382803-2');
</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>radtorch.pipeline</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="radtorch.pipeline.Image_Classification"><code class="flex name class">
<span>class <span class="ident">Image_Classification</span></span>
<span>(</span><span>data_directory, transformations='default', custom_resize='default', device='default', optimizer='Adam', is_dicom=True, label_from_table=False, is_csv=None, table_source=None, path_col='IMAGE_PATH', label_col='IMAGE_LABEL', mode='RAW', wl=None, batch_size=16, test_split=0.2, model_arch='vgg16', pre_trained=True, unfreeze_weights=False, train_epochs=20, learning_rate=0.0001, loss_function='CrossEntropyLoss')</span>
</code></dt>
<dd>
<section class="desc"><p>Creates an Image Classification Pipeline.</p>
<h2 id="inputs">Inputs</h2>
<dl>
<dt><strong><code>data_directory</code></strong></dt>
<dd><strong>[REQUIRED]</strong> [str] target data directory.</dd>
<dt><strong><code>is_dicom</code></strong></dt>
<dd>[boolean] True for DICOM images, False for regular images.(default=True)</dd>
<dt><strong><code>label_from_table</code></strong></dt>
<dd>[boolean] True if labels are to extracted from table, False if labels are to be extracted from subfolders. (default=False)</dd>
<dt><strong><code>is_csv</code></strong></dt>
<dd>[boolean] True for csv, False for pandas dataframe.</dd>
<dt><strong><code>table_source</code></strong></dt>
<dd>[str or pandas dataframe object] source for labelling data. (default=None)
This is path to csv file or name of pandas dataframe if pandas to be used.</dd>
<dt><strong><code>path_col</code></strong></dt>
<dd>[str] name of the column with the image path. (default='IMAGE_PATH')</dd>
<dt><strong><code>label_col</code></strong></dt>
<dd>[str] name of the label/class column. (default='IMAGE_LABEL')</dd>
<dt><strong><code>mode</code></strong></dt>
<dd>[str] output mode for DICOM images only. (default='RAW')
options:
RAW= Raw pixels,
HU= Image converted to Hounsefield Units,
WIN= 'window' image windowed to certain W and L,
MWIN = 'multi-window' converts image to 3 windowed images of different W and L (specified in wl argument) stacked together].</dd>
<dt><strong><code>wl</code></strong></dt>
<dd>[list] list of lists of combinations of window level and widths to be used with WIN and MWIN. (default=None)
In the form of : [[Level,Width], [Level,Width],&hellip;].
Only 3 combinations are allowed for MWIN (for now).</dd>
<dt>transformations:[pytorch transforms] pytroch transforms to be performed on the dataset. (default=Convert to tensor)</dt>
<dt><strong><code>custom_resize</code></strong></dt>
<dd>[int] by default, a radtorch pipeline will resize the input images into the default training model input image size as demosntrated in the table shown in radtorch home page. This default size can be changed here if needed.</dd>
<dt><strong><code>batch_size</code></strong></dt>
<dd>[int] batch size of the dataset (default=16)</dd>
<dt><strong><code>test_split</code></strong></dt>
<dd>[float] percentage of dataset to use for validation. Float value between 0 and 1.0. (default=0.2)</dd>
<dt><strong><code>model_arch</code></strong></dt>
<dd>[str] PyTorch neural network architecture (default='vgg16')</dd>
<dt><strong><code>pre_trained</code></strong></dt>
<dd>[boolen] Load the pretrained weights of the neural network. If False, the last layer is only retrained = Transfer Learning. (default=True)</dd>
<dt><strong><code>unfreeze_weights</code></strong></dt>
<dd>[boolen] if True, all model weights, not just final layer, will be retrained. (default=False)</dd>
<dt><strong><code>train_epochs</code></strong></dt>
<dd>[int] Number of training epochs. (default=20)</dd>
<dt><strong><code>learning_rate</code></strong></dt>
<dd>[float] training learning rate. (default = 0.0001)</dd>
<dt><strong><code>loss_function</code></strong></dt>
<dd>[str] training loss function. (default='CrossEntropyLoss')</dd>
<dt><strong><code>optimizer</code></strong></dt>
<dd>[str] Optimizer to be used during training. (default='Adam')</dd>
<dt><strong><code>device</code></strong></dt>
<dd>[str] device to be used for training. This can be adjusted to 'cpu' or 'cuda'. If nothing is selected, the pipeline automatically detects if cuda is available and trains on it.</dd>
</dl>
<h2 id="outputs">Outputs</h2>
<dl>
<dt><strong><code>Output</code></strong></dt>
<dd>Image Classification Model</dd>
</dl>
<p>Examples:</p>
<pre><code>from radtorch import pipeline

classifier = pipeline.Image_Classification(data_directory='path to data')
classifier.train()
classifier.metrics()

</code></pre>
<p><img alt="" src="pass.jpg"></p></section>
<h3>Methods</h3>
<dl>
<dt id="radtorch.pipeline.Image_Classification.confusion_matrix"><code class="name flex">
<span>def <span class="ident">confusion_matrix</span></span>(<span>self, target_data_set='default', target_classes='default', figure_size=(8, 6))</span>
</code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="radtorch.pipeline.Image_Classification.dataset_info"><code class="name flex">
<span>def <span class="ident">dataset_info</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Displays Dataset Information.</p></section>
</dd>
<dt id="radtorch.pipeline.Image_Classification.export_model"><code class="name flex">
<span>def <span class="ident">export_model</span></span>(<span>self, output_path)</span>
</code></dt>
<dd>
<section class="desc"><p>Exports the trained model into a target file.</p></section>
</dd>
<dt id="radtorch.pipeline.Image_Classification.inference"><code class="name flex">
<span>def <span class="ident">inference</span></span>(<span>self, test_img_path, transformations='default')</span>
</code></dt>
<dd>
<section class="desc"><p>Performs inference on target DICOM image using a trained classifier.</p></section>
</dd>
<dt id="radtorch.pipeline.Image_Classification.info"><code class="name flex">
<span>def <span class="ident">info</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Displays Image Classification Pipeline Parameters.</p></section>
</dd>
<dt id="radtorch.pipeline.Image_Classification.metrics"><code class="name flex">
<span>def <span class="ident">metrics</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Display the training metrics.</p></section>
</dd>
<dt id="radtorch.pipeline.Image_Classification.roc"><code class="name flex">
<span>def <span class="ident">roc</span></span>(<span>self, target_data_set='default', auc=True, figure_size=(10, 10))</span>
</code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="radtorch.pipeline.Image_Classification.sample"><code class="name flex">
<span>def <span class="ident">sample</span></span>(<span>self, num_of_images_per_row=5, fig_size=(10, 10), show_labels=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Displays sample of the training dataset.</p></section>
</dd>
<dt id="radtorch.pipeline.Image_Classification.set_trained_model"><code class="name flex">
<span>def <span class="ident">set_trained_model</span></span>(<span>self, model_path, mode)</span>
</code></dt>
<dd>
<section class="desc"><p>Loads a previously trained model into pipeline</p>
<h2 id="inputs">Inputs</h2>
<dl>
<dt><strong><code>model_path</code></strong></dt>
<dd>[str] Path to target model</dd>
<dt><strong><code>mode</code></strong></dt>
<dd>[str] either 'train' or 'infer'.'train' will load the model to be trained. 'infer' will load the model for inference.</dd>
</dl></section>
</dd>
<dt id="radtorch.pipeline.Image_Classification.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, verbose=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Train the created image classifier.</p></section>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="radtorch" href="index.html">radtorch</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="radtorch.pipeline.Image_Classification" href="#radtorch.pipeline.Image_Classification">Image_Classification</a></code></h4>
<ul class="two-column">
<li><code><a title="radtorch.pipeline.Image_Classification.confusion_matrix" href="#radtorch.pipeline.Image_Classification.confusion_matrix">confusion_matrix</a></code></li>
<li><code><a title="radtorch.pipeline.Image_Classification.dataset_info" href="#radtorch.pipeline.Image_Classification.dataset_info">dataset_info</a></code></li>
<li><code><a title="radtorch.pipeline.Image_Classification.export_model" href="#radtorch.pipeline.Image_Classification.export_model">export_model</a></code></li>
<li><code><a title="radtorch.pipeline.Image_Classification.inference" href="#radtorch.pipeline.Image_Classification.inference">inference</a></code></li>
<li><code><a title="radtorch.pipeline.Image_Classification.info" href="#radtorch.pipeline.Image_Classification.info">info</a></code></li>
<li><code><a title="radtorch.pipeline.Image_Classification.metrics" href="#radtorch.pipeline.Image_Classification.metrics">metrics</a></code></li>
<li><code><a title="radtorch.pipeline.Image_Classification.roc" href="#radtorch.pipeline.Image_Classification.roc">roc</a></code></li>
<li><code><a title="radtorch.pipeline.Image_Classification.sample" href="#radtorch.pipeline.Image_Classification.sample">sample</a></code></li>
<li><code><a title="radtorch.pipeline.Image_Classification.set_trained_model" href="#radtorch.pipeline.Image_Classification.set_trained_model">set_trained_model</a></code></li>
<li><code><a title="radtorch.pipeline.Image_Classification.train" href="#radtorch.pipeline.Image_Classification.train">train</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>